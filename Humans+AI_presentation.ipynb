{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# User Experience with Artificial Intelligence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"Machine Learning\" is becoming just another tool in a developers toolbox. \n",
    "\n",
    "As per [StackOverflow's 2018 survey](https://insights.stackoverflow.com/survey/2018/):\n",
    "* PyTorch and TensorFlow compete with React as most loved tool by 70% of devs\n",
    "* 47.8% say \"The developers or the people creating the AI\" are primarily responsible for ML ramifications\n",
    "* 72.8% say \"I'm excited about the possibilities more than worried about the dangers.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Google's UX team \n",
    "  * has an effort called [\"Human-Centered Machine Learning\"](https://medium.com/google-design/human-centered-machine-learning-a770d10562cd) to guide conversations \n",
    "  * Few great publications on [UX of AI](https://design.google/library/ux-ai/) from which I shamelessly stole the title\n",
    "* NeurIPS 2018 had \n",
    "  * a workshop on [\"Ethical, Social and Governance Issues in AI\"](https://nips.cc/Conferences/2018/Schedule?showEvent=10940)\n",
    "  * a tutorial on [\"Common Pitfalls for Studying the Human Side of Machine Learning\"](https://nips.cc/Conferences/2018/Schedule?showEvent=10981)\n",
    "  * invited talks on [Algorithmic Bias](https://nips.cc/Conferences/2018/Schedule?showEvent=12870), [Public Policy](https://nips.cc/Conferences/2018/Schedule?showEvent=12483) and [\"Human-AI Trust\"](https://nips.cc/Conferences/2018/Schedule?showEvent=12301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine Learning has the potential to really affect people's lives, for better or for worse, it's new and interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But it's a bit like radioactivity\n",
    "* **1911** Marie Curie discovers it\n",
    "* **1925** your watch glows in the dark but all the painters got cancer \n",
    "* **1945** Trinity test and Hiroshima\n",
    "* **1954** first nuclear power plant in Obninsk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<style>\n",
    "p {\n",
    "  font-size: 10px\n",
    "}</style>\n",
    "For Machine Learning\n",
    "* **1954-1971** Few people have a neat way of building models, get excited <sup>[1](https://en.wikipedia.org/wiki/Artificial_intelligence#History), [2](https://en.wikipedia.org/wiki/Alexey_Ivakhnenko)</sup>\n",
    "* **1973-1990** Machine Translation doesn't work and a famous guy 'proves' AI is bunk <sup>[3](https://en.wikipedia.org/wiki/AI_winter)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* **2012&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;** Wait maybe not, old bug is fixed and everybody is excited again.<sup>[4](https://en.wikipedia.org/wiki/Deep_learning#Deep_learning_revolution)</sup>\n",
    "* **2016&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;** Cambridge Analytica makes a mess <sup>[5](https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal)</sup>\n",
    "* **2016-2018** Everybody gets a creepy talking speaker thing for their house and car. \n",
    "* **2018&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;** We hear about Cambridge Analytica but it's a bit late\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretability and Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "David J. Spiegelhalter of the Royal Society suggests this:\n",
    "\n",
    "\"Realising the benefits of open data requires\n",
    "effective communication through a more intelligent\n",
    "openness: \n",
    "* data must be **accessible** and readily\n",
    "located; \n",
    "* they must be **intelligible** to those who wish\n",
    "to scrutinise them; \n",
    "* data must be **assessable** so that judgments can be made about their reliability and the\n",
    "competence of those who created them; \n",
    "* and they must be **usable** by others. \"\n",
    "\n",
    "*-Society, Royal. \"Science as an Open Enterprise.\" (2012).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Machine learning models can follow these principles.\n",
    "* Users have a 'right to explanation'<sup>[1](https://en.wikipedia.org/wiki/Right_to_explanation)</sup>\n",
    "* This is the law in contexts like: \n",
    "  * credit scores in the United States (ECOA)\n",
    "  * general data in the EU (GDPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Christoph Molnar has a great book on this:\n",
    "[\"Interpretable Machine Learning:\n",
    "A Guide for Making Black Box Models Explainable\"](https://christophm.github.io/interpretable-ml-book/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next few slides:\n",
    "\n",
    "* Interpretability vs explainability\n",
    "* Implicitly interpretable models\n",
    "* Review of model agnostic methods \n",
    "* Example based explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ethics in AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next slides:\n",
    "\n",
    "Approaches to: \n",
    "* Fairness\n",
    "* Privacy\n",
    "* Trust\n",
    "* Inclusion\n",
    "\n",
    "https://twimlai.com/tag/fairness/\n",
    "\n",
    "https://www.news.gatech.edu/2016/02/29/emergencies-should-you-trust-robot\n",
    "\n",
    "https://design.google/library/fair-not-default/\n",
    "\n",
    "https://github.com/dssg/aequitas \n",
    "\n",
    "https://pypi.org/project/aif360/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Designing with AI in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Donald Norman, author of \"The Design of Everyday Things\" suggests designing to these principles:\n",
    "* **visibility** - what you see\n",
    "* **affordance** - cues for interaction\n",
    "* **mapping** - connecting control and effect\n",
    "* **feedback** - response to interaction\n",
    "* **constraints** - what you can't do\n",
    "* **consistancy** - helping users learn from patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next slides: \n",
    "Applying these principles to AI\n",
    "\n",
    "https://design.google/library/ai/\n",
    "\n",
    "https://medium.com/google-design/human-centered-machine-learning-a770d10562cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "presentation",
   "language": "python",
   "name": "presentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
